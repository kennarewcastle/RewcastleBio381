---
title: "Homework 6"
author: "Kenna Rewcastle"
date: "2/21/2018"
output: 
  html_document: 
    highlight: tango
    theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

#### Open libraries

```{r}
library(ggplot2) # for graphics
library(MASS) # for maximum likelihood estimation
library(gridExtra) # for displaying histograms side by side
```

#### Read in data vector

To illustrate, we will generate some fake data here:

```{r}
# quick and dirty, a truncated normal distribution to work on the solution set

#z <- rnorm(n=3000,mean=0.2)
#z <- data.frame(1:3000,z)
#names(z) <- list("ID","myVar")
#z <- z[z$myVar>0,]
#str(z)
#summary(z$myVar)
```

Fake data has been commented out. This data set is scaled to eliminate negative numbers so that the fit of the normal distribution can be compared to the exponential and gamma distriubtions. 

```{r}
z <- read.table("mean_dat.csv",header=TRUE,sep=",", stringsAsFactors=FALSE)
names(z)
d13<-z$d13
myVar<-d13+100 # Scaled all d13 values by 100 so that the values are positive, necessary for exponential and gamma distributions
ID<-z$unique_ID
z<-data.frame(ID,myVar) # Constrain dataframe down to single variable (scaled delta13) and an integer ID
head(z)
```

#### Plot histogram of data

Plot a histogram of the data, using a modification of the code from lecture. Here we are switching from `qplot` to `ggplot` for more graphics options. We are also rescaling the y axis of the histogram from counts to density, so that the area under the histogram equals 1.0.

```{r}
p1 <- ggplot(data=z, aes(x=myVar, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 
print(p1)
```

#### Add empirical density curve

Now modify the code to add in a kernel density plot of the data. This is an empirical curve that is fitted to the data. It does not assume any particular probability distribution, but it smooths out the shape of the histogram:

```{r}
p1 <-  p1 +  geom_density(linetype="dotted",size=0.75)
print(p1)
```

#### Get maximum likelihood parameters for `normal`

Next, fit a normal distribution to your data and grab the maximum likelihood estimators of the two parameters of the normal, the mean and the variance:

```{r}
normPars <- fitdistr(z$myVar,"normal")
print(normPars)
str(normPars)
normPars$estimate["mean"] # note structure of getting a named attribute

```
#### Plot `normal` probability density

Now let's call the `dnorm` function inside ggplot's `stat_function` to generate the probability density for the normal distribution. Read about `stat_function` in the help system to see how you can use this to add a smooth function to any ggplot. Note that we first get the maximum likelihood parameters for a normal distribution fitted to thse data by calling `fitdistr`. Then we pass those parameters (`meanML` and `sdML` to `stat_function`:

```{r}

meanML <- normPars$estimate["mean"]
sdML <- normPars$estimate["sd"]

xval <- seq(0,max(z$myVar),len=length(z$myVar))

 stat <- stat_function(aes(x = xval, y = ..y..), fun = dnorm, colour="red", n = length(z$myVar), args = list(mean = meanML, sd = sdML))
 p1 + stat
```

Notice that the best-fitting normal distribution (red curve) for these data actually has a biased mean. That is because the data set has no negative values, so the normal distribution (which is symmetric) is not working well.

#### Plot `exponential` probability density

Now let's use the same template and add in the curve for the exponential:

```{r}
expoPars <- fitdistr(z$myVar,"exponential")
rateML <- expoPars$estimate["rate"]

stat2 <- stat_function(aes(x = xval, y = ..y..), fun = dexp, colour="blue", n = length(z$myVar), args = list(rate=rateML))
 p1 + stat + stat2
```

#### Plot `uniform` probability density

For the uniform, we don't need to use `fitdistr` because the maximum likelihood estimators of the two parameters are just the minimum and the maximum of the data:

```{r}
stat3 <- stat_function(aes(x = xval, y = ..y..), fun = dunif, colour="darkgreen", n = length(z$myVar), args = list(min=min(z$myVar), max=max(z$myVar)))
 p1 + stat + stat2 + stat3
```


#### Plot `gamma` probability density


```{r}
gammaPars <- fitdistr(z$myVar,"gamma")
shapeML <- gammaPars$estimate["shape"]
rateML <- gammaPars$estimate["rate"]

stat4 <- stat_function(aes(x = xval, y = ..y..), fun = dgamma, colour="brown", n = length(z$myVar), args = list(shape=shapeML, rate=rateML))
 p1 + stat + stat2 + stat3 + stat4
```


#### Plot `beta` probability density
This one has to be shown in its own plot because the raw data must be rescaled so they are between 0 and 1, and then they can be compared to the beta.

```{r}

pSpecial <- ggplot(data=z, aes(x=myVar/(max(myVar + 0.1)), y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) + 
  xlim(c(0,1)) +
  geom_density(size=0.75,linetype="dotted")

betaPars <- fitdistr(x=z$myVar/max(z$myVar + 0.1),start=list(shape1=1,shape2=2),"beta")
shape1ML <- betaPars$estimate["shape1"]
shape2ML <- betaPars$estimate["shape2"]

statSpecial <- stat_function(aes(x = xval, y = ..y..), fun = dbeta, colour="orchid", n = length(z$myVar), args = list(shape1=shape1ML,shape2=shape2ML))
pSpecial + statSpecial
```


#### Reflections on distribution fit

The `gamma` distribution appears to fit this data set best, though the fit is marginally better than that of the `normal` distribution which does not require scaling the data to yield postiive values. Therefore, I will use the `normal` distribution to describe the "un-scaled" original data. Using my data and the normal distribution fitted to that data, I will find the maximum likelihood estimates for the descriptive parameters of this distribution, the mean and standard deviation, and will simulate a data set of the same size using these parameter values.

#### Maximum likelihood parameter estimates

This data frame is the original data, un-scaled, that will be used to simulate a fake data set using the MLE for mean and standard deviation from a normal distribution.

```{r}
z <- read.table("mean_dat.csv",header=TRUE,sep=",", stringsAsFactors=FALSE)
names(z)
ID<-z$unique_ID
myVar<-z$d13
z<-data.frame(ID,myVar)
head(z)
```

Going back to the `normal` distribution code above, we find that the MLE for the mean is -13.42 and is and the MLE for the standard deviation is 12.07. 

```{r}
normPars <- fitdistr(z$myVar,"normal")

meanML <- normPars$estimate["mean"]
sdML <- normPars$estimate["sd"]

print(meanML)
print(sdML)
```

#### Simulating data from `normal` distribution MLEs

```{r}
length(z$myVar) # 76
fakeVar<-rnorm(n=76,mean=meanML,sd=sdML) # Vector of 76 elements drawn from normal distribution with the same mean and sd parameter values as above.
summary(fakeVar)

fakeID<-seq(from=1,to=76)
fakeDat<-data.frame(fakeID,fakeVar)
head(fakeDat)
```

#### Histogram of simulated data with empirical density curve

Empirical density curve is not associated with any stats, but simply smooths out the histogram.

```{r}
fake1 <- ggplot(data=fakeDat, aes(x=fakeVar, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 

fake1 <-  fake1 +  geom_density(linetype="dotted",size=0.75)
print(fake1)
```

#### Comparing the distributions of simulated and original data

```{r}
p1 <- ggplot(data=z, aes(x=myVar, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 

p1 <-  p1 +  geom_density(linetype="dotted",size=0.75)


grid.arrange(fake1,p1,ncol=2)
```

The main difference between the density profiles of the simulated and original data is that the simulated data from the normal distribution model constrains the range of the data by minimizing the tail on the right. The variation in the simulated data is essentially distributed equally on either side of the mean instead of being skewed to the right as in the original data.
